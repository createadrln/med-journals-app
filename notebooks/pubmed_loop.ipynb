{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c664988",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dump() missing 1 required positional argument: 'fp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m data_dict = json.dumps(xmltodict.parse(Bs_data.prettify()))\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../raw_data/pubmed_full_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCURRENT_PAGE\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     64\u001b[39m     json.dump(json.loads(data_dict), json_file, indent=\u001b[32m4\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: dump() missing 1 required positional argument: 'fp'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import xmltodict\n",
    "\n",
    "def fetch_pubmed_data(term, page = 1, type='full'):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': term,\n",
    "        'sort': 'most_recent',\n",
    "        'datetype': 'edat',\n",
    "        'reldate': 2,\n",
    "        'retmax': 300,\n",
    "        'retstart': (page - 1) * 300,\n",
    "        'retmode': 'json',\n",
    "        'apikey': None\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        id_list = response.json().get('esearchresult', {}).get('idlist', [])\n",
    "\n",
    "        if type == 'detail':\n",
    "            detail_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
    "            details_params = {\n",
    "                'db': 'pubmed',\n",
    "                'id': ','.join(id_list),\n",
    "                'retmode': 'json',\n",
    "                'apikey': None\n",
    "            }\n",
    "            detail_response = requests.get(detail_url, params=details_params)\n",
    "            return detail_response.json()\n",
    "\n",
    "        full_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "        full_params = {\n",
    "            'db': 'pubmed',\n",
    "            'id': ','.join(id_list),\n",
    "            'rettype': 'medline',\n",
    "            'retmode': 'xml',\n",
    "            'apikey': None\n",
    "        }\n",
    "        full_response = requests.get(full_url, params=full_params)\n",
    "        return full_response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while querying PubMed: {e}\")\n",
    "\n",
    "PAGES = 50\n",
    "CURRENT_PAGE = 1\n",
    "\n",
    "while CURRENT_PAGE + 1 < PAGES:\n",
    "    data = fetch_pubmed_data('COVID-19', CURRENT_PAGE)\n",
    "    CURRENT_PAGE += 1\n",
    "\n",
    "    if data.status_code != 200:\n",
    "        break\n",
    "\n",
    "    data_dict = {}\n",
    "    Bs_data = BeautifulSoup(data.text, 'xml')\n",
    "    data_dict = json.dumps(xmltodict.parse(Bs_data.prettify()))\n",
    "\n",
    "    with open(f'../raw_data/pubmed_full_{CURRENT_PAGE - 1}.json', 'w', encoding=\"utf-8\") as json_file:\n",
    "        print(json.loads(data_dict))\n",
    "        json.dump(json.loads(data_dict), json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
